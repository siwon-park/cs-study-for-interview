# 09_메모리 관리(Memory Management)

## 1. 메모리 (Memory)

### 1) 메모리 관리의 필요성

- 프로세스 입장: 더 많은 메모리, 자원을 사용하고 싶음
- 메모리 관리자 입장: 효율적으로 메모리를 관리하여 많은 프로세스에게 할당

<br>

### 2) 컴파일 vs 인터프리터

#### (1) 컴파일 과정

`소스 코드 → 컴파일 → 목적 코드 → 링크(링킹)` → 실행

- 소스 코드 ~ 링크까지의 단계를 컴파일이라고 부름
- 링크 단계에서 라이브러리를 링크한다.
  - 정적 라이브러리
    - 컴파일 시점에 프로그램에 포함되는 라이브러리
  - 동적 라이브러리
    - 실행 시점에 메모리에 로드되는 라이브러리

※ 분할 컴파일: 소스 코드를 복사하여 합친 다음 컴파일 하는 것은 에러를 초래할 수도 있음. 하지만 분할 컴파일 하여 목적 코드를 만들고 이를 합치면 에러가 발생하지 않음. 목적 코드는 이미 분석이 끝난 코드이기 때문.

※ 컴파일이 중요한 이유?

- 오류 발견 및 최적화(필요 없는, 안 쓰이는 객체 없애기)
-  컴파일은 컴퓨터가 이해하기 위한 언어로 변환하는 과정이지만, 메모리와도 중요한 관련이 있다.
- 컴파일러는 모든 변수를 메모리 주소로 바꾸고 기계어로 변환된 파일을 만드는 것임. 

#### (2) 링킹 (Linking)

※ Linking: 컴파일된 파일을 묶어 하나의 실행 파일로 만드는 것을 말함

- 정적 링킹 (Static Linking) - 정적 라이브러리 (Static Library)
  - 라이브러리가 실행 파일의 '코드'에 포함됨 => 예) print()함수의 소스코드를 실행 파일로 포함시키는 것
  - 실행파일의 크기가 커지며, 동일한 라이브러리를 각각의 프로세스가 메모리에 올리는 경우도 있게되므로 메모리 낭비 발생

- 동적 링킹 (Dynamic Linking) - 동적 라이브러리 (Dynamic Library)
  - 라이브러리가 프로그램 실행 시 연결(Link)됨 => 예) import의 개념 또는 print()함수를 그냥 호출만 함
  - 라이브러리가 메모리에 있으면 해당 주소로 가서 읽고 아니면 디스크에서 읽어옴
  - OS의 도움이 필요한 방법

#### (3) 인터프리터

코드를 한 줄 한 줄 해석하여 실행함.

<br>

### 3) 메모리의 종류

#### (1) 물리 메모리 (Physical Memory)

물리 메모리는 보통 "메인 메모리", "주 메모리"라고도 한다. 실제 컴퓨터에 RAM이라는 이름으로 장착된 칩을 의미한다.

#### (2) 가상 메모리 (Virtual Memory)

운영체제가 제공하는 메모리 관리 기법 중 하나로, 실제 물리 메모리보다 큰 메모리 공간을 사용할 수 있도록 해준다.

가상 메모리는 물리 메모리와 스왑 영역을 합한 공간이다.

- 가상 메모리 = 물리 메모리 + 스왑 영역
- 스왑 영역은 디스크 공간에 존재하는 영역이지만 메모리 관리자에 의해 관리된다는 특이점이 있다.

현대 메모리 관리의 핵심이며, `프로세스가 올라갈 메모리 위치와 메모리 크기에 신경쓰지 않도록 하기 위함에 목적`이 있다.

- 물리적 메모리 크기를 뛰어 넘는 메모리 자원을 요구하는 프로그램을 효율적으로 실행하기 위해
- 주소를 가상화하여 프로세스를 서로 격리하고, 다른 프로세스로부터 보호하기 위해

<br>

### 4) 메모리 관리 작업

#### (1) 메모리 로딩

실행할 프로세스와 데이터를 메모리에 가져오는 작업으로

- 모든 것을 한 번에 가져오기도 하지만,
- 필요할 때만 가져오기도 한다.

#### (2) 메모리 배치

프로세스, 데이터를 메모리에 어떻게, 어떤 방식으로 배치할 것인가?

- 메모리를 고정적인 크기로 분할하여 프로세스에게 할당 => `페이징(paging)`
- 메모리를 연속적인 공간으로 프로세스의 크기에 맞춰서 할당 => `세그먼테이션(segmentation)`

#### (3) 메모리 재배치

새로운 프로세스를 가져오기 위해 오래된 프로세스를 내보내는 작업

어떤 프로세스를 내보낼 것인가? => `교체 알고리즘`

<br>

### 5) 메모리 구조

메모리 구조는 운영체제 영역과 사용자 프로그램 영역으로 나눌 수 있으며 경계 레지스터에 의해 구분된다.

경계 레지스터 값을 초과하여 운영체제 영역을 침범하려는 프로세스는 강제 종료된다.

![image](https://github.com/siwon-park/cs-study-for-interview/assets/93081720/be71044b-f5e0-4df3-b048-9c192ad81ec4)

<br>

## 2. 메모리 주소 (Memory Address)

### 1) 논리적 주소 (Logical Address, Virtual Address)

프로세스마다 독립적으로 가지는 주소 공간으로 CPU가 프로세스의 메모리 공간을 참조할 때 사용하는 주소로 소프트웨어적인 주소

- 각 프로세스마다 독립적이기 때문에, 같은 논리적 주소가 다른 물리적 주소를 가리킬 수 있음.

컴파일 시에 부여되며, 프로그램과 CPU가 사용하는 주소.

논리적 주소는 MMU(메모리 변환 장치)에 의해서 물리적 주소로 변환된다.

- 이러한 과정을 주소 변환, 주소 바인딩, 주소 맵핑이라고 한다.

<br>

### 2) 물리적 주소 (Physical Address)

실제 메모리(RAM)에 올라가는 물리적인 위치 공간으로 `하드웨어적`으로 접근 가능한 주소.

메모리 하드웨어가 사용하는 주소이다.

MMU를 통해 논리적 주소가 물리적 주소로 변환된다.

<br>

### 3) 심볼릭 주소 (Symbolic Address)

소스 코드 내에서 사용하는 변수나 함수 등의 메모리 위치를 나타내는 주소를 말한다.

사람이 이해하기 쉬운 형태로 컴파일러와 어셈블러에 의해서 논리적 주소로 변환된다.

<br>

## 3. 주소 변환 과정

### 1) 주소 변환

1. 개발자가 소스 코드에 변수명을 작성한다. (심볼릭 주소)
   - 예) `int a = 10;`
2. 컴파일러가 심볼릭 주소를 논리적 주소로 변환한다. (논리적 주소)
   - 예) 변수 a는 논리적 주소 `0x0040`에 위치함
3. MMU가 논리적 주소를 물리적 주소로 변환한다. (물리적 주소)
   - 예) 논리적 주소 0x0040이 MMU를 통해서 물리적 주소 `0x00A0`으로 변환
   - 실제 물리적 메모리(RAM) 상에서 0x00A0 위치에 변수 a가 위치함.

#### (1) Memory Management Unit (MMU)

**논리적 주소를 물리적 주소로 맵핑해주는 하드웨어**

![image](https://github.com/siwon-park/cs-study-for-interview/assets/93081720/5ce671ac-e214-48a5-ac38-ee720c4f5521)

- MMU scheme
  - 사용자 프로세스가 CPU에서 수행되며 `생성해내는 모든 주소값에 대해 재배치 레지스터(relocation register)의 값을 더함`
    - 예) 346 논리적 주소를 요청, relocation register(=base register)가 14000이면 14346번 주소를 요청

- user program은 논리적 주소만 다루며, 물리적 주소는 볼 수도 없고 알 필요도 없다. (메모리 주소 가상화의 장점)

<br>

### 2) 주소 바인딩(Address Binding)

프로그램이 어떤 물리적 주소로 메모리에 올라갈지 물리적 주소를 결정하는 것, 시점

![image](https://user-images.githubusercontent.com/93081720/166854927-ef2c3ad3-4905-431d-848d-f4b0586be724.png)

※ 세 바인딩 시점 모두 메모리 상에 올라가는 주소는 바뀔 수 있지만(앞에 두 케이스는 재컴파일을 통해서) 코드 상의 논리적 주소는 바뀌지 않음을 유의!

#### (1) Compile Time Binding (컴파일 타임 바인딩)

물리적 메모리 주소가 컴파일 시에 정해짐. 컴파일 시 절대 코드(absolute code) 생성

주소 변경을 원할 시(시작 위치 변경을 원할 시) 재컴파일 필요

#### (2) Load Time Binding (로드 타임 바인딩)

Loader의 책임 하에 물리적 메모리 주소를 부여

컴파일러가 재배치 가능 코드(relocation code)를 생성한 경우 가능

Compile time binding처럼 프로그램 시작 후 물리적 주소가 결정된 뒤에는 변화 불가능(재컴파일 필요)

#### (3) Runtime Binding(Executiomn Binding, 실행 바인딩)

프로그램의 수행이 시작된 이후에도 프로세스의 메모리 상 위치 변경이 가능함

CPU가 주소를 참조할 때마다 바인딩을 점검함 => Address Mapping Table

동적인 주소 변환을 위해 하드웨어적인 지원이 필요(`MMU`)

<br>

## 3. 메모리 로딩(Memory Loading)

※ `로딩(Loading)`: 프로세스를 메모리로 올리는 것

메모리 로딩에는 동적 로딩, 오버레이, 스와핑, 다이나믹 링킹이 있다.

<br>

### 1) 동적 로딩 (Dynamic Loading)

해당 프로세스 루틴이 불려질 때마다 메모리에 loading하는 방식

Memory Utilization의 향상을 불러옴

OS의 특별한 지원 없이 프로그램 자체에서 구현 가능(OS는 라이브러리를 통해 지원 가능) => 프로그래머가 자세히 코딩할 필요 X

※ Static Loading(정적 로딩): 프로세스 전체를 메모리에 미리 올리는 것 => 가끔 쓰거나 안 쓰는 루틴이 있을 수도 있어 비효율적임

 <br>

### 2) 오버레이 (Overlays)

메모리에 프로세스의 부분 중 실제 필요한 정보만 적당한 크기로 가져와서 메모리에 올리는 것. 이 덕분에 `전체 메모리보다 큰 메모리를 요구하는 프로그램을 실행 가능`

- 예) 포토샵 프로그램을 실행했을 때 전체를 다 올리면 메모리를 초과하여 프로그램 실행이 불가능한데, 그게 아니라 AI나 보정 기능은 실행하다가 도중에 필요하면 메모리에 올린다.

프로세스의 크기가 메모리보다 클 때 유용함

OS의 지원 없이 코딩에 의해 구현되어야함 but 프로그래밍이 복잡함

<br>

### 3) 스와핑 (Swapping)

프로세스를 일시적으로 메모리에서 backing store로 쫓아내거나(swap out), 쫓아냈던 프로세스를 다시 불러들이는 것(swap in)으로 `중기 스케줄러(swapper)`에 의해 동작함

![image](https://github.com/siwon-park/cs-study-for-interview/assets/93081720/1443e9cb-5f7c-4354-a5d7-a9262e5c3825)

- 스왑 영역
  - 저장 장치(HDD)의 영역이지만, 메모리 관리자가 관리하는 영역이다.
  - 메모리가 모자라서 쫓겨난 프로세스들이 보관되는 영역을 말한다.
  - 사용자 프로세스는 실제 메모리 + 스왑 영역을 합쳐서 메모리 크기라고 인식한다. (가상 메모리)

- swap out
  - 메모리에서 프로세스를 일시적으로 내쫓음(일반적으로 우선순위가 낮은 것)
- swap in
  - 쫓아냈던 것을 다시 불러들임
  - Compile time binding/Load time binding에서는 반드시 원래의 물리적 위치로 swap in되어야 함(두 케이스는 재컴파일을 하지 않는 이상 물리적 주소가 바뀌지 않으니까)
  - 반면, Runtime binding에서는 추후 빈 메모리 영역의 아무곳이나 올릴 수 있음

<br>

## 4. 메모리 할당(Allocation Of Physical Memory)

위에서 `로딩`이 프로그램을 실행시켜 `프로세스를 메모리에 올리는 행동`이라고 언급했다. 즉, 프로그램을 실행하면 프로세스는 메모리에 올라간다는 말과 같다.

메모리 영역은 OS 상주 영역과 사용자 프로세스 영역으로 나뉘는데, 이 중 사용자 프로세스 영역에 대해서 `프로세스들이 메모리를 적절히 차지(활용)해서 실행될 수 있도록 프로세스에게 메모리를 할당하는 기법`이 필요한데, 이를 `메모리 할당 기법`이라고 한다.

메모리 할당 기법에는 `연속 할당 기법`과 `불연속 할당 기법`이 있다.

<br>

### 1) 연속 할당(Continuous Allocation)

각각의 프로세스가 메모리의 `연속적인 공간에 적재`되도록 하는 것

![image](https://user-images.githubusercontent.com/93081720/166858926-05addd16-1af2-4855-b2e8-a029ff62be79.png)

#### (1) 고정 파티션 방식(Fixed Partition)

미리 물리적 메모리를 몇 개의 구역으로 분할해서 나눔

분할 크기가 모두 동일하거나 서로 다른 방식이 존재하며, 하나의 분할된 구역 당 하나의 프로그램을 적재시킴

- 융통성이 없다는 단점이 존재함 => 동시에 메모리에 로드되는 프로그램의 수가 고정적일 수 있음(최대 수행 가능 프로그램 크기 제한)

- 고정 파티션 방식에서는 `외부 단편화와 내부 단편화 둘 다 발생`할 수 있음.

  - `외부 조각(external fragment)`: 올리려는 프로그램의 크기보다 분할된 메모리의 크기가 작아서 프로그램이 배정되지 않은 빈 공간 임에도 프로그램이 올라갈 수 없는 공간
    - 외부 조각이 발생하는 경우를 `외부 단편화`라고 한다.


  - `내부 조각(internal fragment)`: 프로그램에게 메모리가 할당되었지만, 프로그램의 크기보다 분할된 메모리의 크기가 커서 분할된 메모리 내에 쓰이지 않고 남아 있는 공간 
    - 내부 조각이 발생하는 경우를 `내부 단편화`라고 한다.


=> **들어오는 프로그램의 크기가 다양하니 그때 그때마다 조각에 대한 해석은 달라질 수 있음** (흔히 둘 중 하나만 발생할 수 있다고들 오해하는데, 고정 분할 방식에서는 내부 단편화, 외부 단편화 둘 다 발생할 수 있음을 유의)

#### ※ 메모리 단편화(Memory Fragmentation)

|             내부 단편화(Internal Fragmentation)              |             외부 단편화(External Fragmentation)              |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| ![image](https://github.com/siwon-park/cs-study-for-interview/assets/93081720/5f606066-7c24-4c69-b901-a5313740f365) | ![image](https://github.com/siwon-park/cs-study-for-interview/assets/93081720/5a0b06cb-b99e-4e5e-b6ce-9ad0e4e80348) |

- `내부 단편화(Internal Fragmentation)`
  - 메모리 내 사용자 영역이 실행 프로그램보다 커서 프로그램의 사용 공간을 할당 후 사용되지 않고 남게 되는 현상
  - 위의 예시에서 100MB의 메모리가 있어서 80MB를 차지하는 프로세스에게 할당했지만 20MB가 쓰이지 않고 남게 됨
- `외부 단편화(External Fragmentation)`
  - 남아있는 총 메모리 공간이 요청한 메모리 공간보다 크지만, 남아있는 공간이 연속적(contiguous)이지 않아 발생하는 현상
  - 위의 예시에서 총 100MB(50MB + 50MB)가 남아있지만 80MB의 프로세스를 메모리에 올리지 못하는 현상 발생

#### (2) 가변 파티션 방식(Variable Partition, 동적 파티션 방식)

프로그램이 들어올 때마다 프로그램의 크기를 고려해서 할당함. 메모리 분할의 크기, 개수가 동적으로 변함.

기존 프로세스가 메모리를 다 사용하고 난 이후에 나가면, 사이 사이에 가용 가능한 빈 공간이 생기는 문제 발생.

- 내부 조각은 발생하지 않고 외부 조각만 발생(`외부 단편화만 발생`)
- 이를 동적 메모리 할당 문제라고 한다.

#### (3) 동적 메모리 할당 문제 해결 방법 (Dynamic Storage Allocation Problem)

가변 분할 방식에서 크기가 N인 프로그램을 메모리에 할당시키는 요청을 만족하는 가장 적절한 `Hole`을 찾는 문제

※ `Hole(가용 메모리 공간)`

연속 할당 기법을 사용하면 다양한 크기의 hole들이 메모리 여러 곳에 생겨 흩어지게 됨.

따라서 프로세스가 도착했을 때, 수용가능한 hole이 있다면 해당 hole에 할당함

이렇게 동작하기 위해선 할당 공간과 가용공간(hole)에 대한 정보를 OS에서 유지하고 있어야함

=> **실험 결과 First-Fit, Best-Fit이 Worts-Fit보다 속도/공간면에서 효율적임**

##### 최초 적합(First Fit)

현재 프로세스에게 할당 가능한 크기의 가용 메모리 공간 중 `가장 먼저 찾은 공간`에 할당하는 방식.

메모리에 존재하는 가용 공간을 차례대로 살피면서 가용 공간이 현재 프로세스의 크기보다 작으면 건너뛰다가 최초로 가용 가능한 공간이 발견되면 할당하는 방식이다.

찾자마자 바로 할당하면 되기 때문에 시간적인 측면에서 효율적이다.

##### 최적 적합(Best Fit)

현재 프로세스에게 할당 가능한 크기의 가용 메모리 공간 중 `프로세스의 크기와 가장 가까운 크기의 공간`에 할당하는 방식

모든 가용 공간을 탐색한 다음에 현재 프로세스의 크기 이상이면서 가장 작은 공간을 프로세스에게 할당하는 방식이다.

모든 공간을 탐색해야 하기 때문에 시간적으로는 비효율적이지만 공간적으로는 효율적이다.

##### 최악 적합(Worst Fit)

가용 가능한 공간 중에서 `가장 큰 공간을 찾아서 그 곳에 프로세스를 할당`하는 방식

#### (4) 메모리 압축 (Memory Compaction)

사용 중인 메모리 영역을 한 군데로 몰아서 홀들을 한 군데로 모으게 되어 큰 홀을 만드는 것

- 디스크 정리는 빈 메모리를 한 군데로 모으는 것이므로 약간 다른 개념임
- 압축은 사용 중인 메모리임을 유의!

![image](https://github.com/siwon-park/cs-study-for-interview/assets/93081720/644da155-86f7-40f1-8067-5be02194e5d6)

실행 중인 프로그램에 대한 메모리 영역 이동이므로 매우 비용이 많이 드는 방법이며, 어떤 프로그램을 이동시킬 것인가에 대한 문제도 처리해야함 => 최소한의 메모리 이동으로 압축하는 것은 매우 복잡한 문제

프로세스의 주소가 실행 시간에 동적으로 재배치 가능한 경우에만 실현 가능(Runtime Binding일 경우에만 가능)

<br>

### 2) 불연속 할당(Non Continuous Allocation, Uncontinuous Allocation)

각각의 프로세스가 메모리에 연속적으로 올라가는 형태가 아니라 `여러 영역에 분산되어 올라갈 수 있는 할당 방식`을 의미한다.

현대 운영체제가 택한 메모리 할당 방식이다.

불연속 할당의 대표적인 기법에는 `페이징(paging)`과 `세그먼테이션(segmentation)`이 있다.

- 페이지(Page): 프로세스를 고정된 크기의 작은 블록들로 나눈 것(Fixed)
- 세그먼트(Segment): 서로 다른 크기의 논리적 단위(Dynamic)
- 프레임(Frame): 페이지 크기와 같은 주 기억장치의 메모리 블록

#### (1) 페이징(paging) 기법

가상메모리를 같은 크기의 블록으로 나눈 것을 `페이지`라고 하고 물리 메모리(RAM)를 페이지와 같은 크기의 블록으로 나눈 것을 `프레임`이라고 한다.

페이지는 크기들이 고정되어 있기 때문에 프로세스의 크기가 항상 페이지의 크기의 배수가 된다는 보장이 없다. 따라서 내부 단편화가 발생하게 된다.

- 주소 변환 기법: 논리적 메모리가 `페이지 테이블(page table)`을 거쳐서 물리적 메모리 주소로 변환된다.
  - 특정 프로세스의 몇 번째 페이지가 물리적 메모리의 몇 번째 프레임에 들어가 있는지에 대한 정보를 가진 테이블
- 페이징 기법에서는 모든 프로세스가 주소 변환을 위한 페이지 테이블을 갖는 구조이다.
  - 따라서 프로세스의 크기나 수가 많으면 그만큼 페이지 테이블의 크기와 수도 많아진다.
- 페이지 테이블은 메인 메모리에 위치한다.
  - 따라서 사실상 메인 메모리 접근이  `2번` 발생한다. (1. 페이지 테이블에 접근, 2. 실제 자료구조/인스트럭션에 접근)
  - 이를 해결하기 위해 캐싱된 페이지 테이블인 `TLB(Translagtion Look-ahead Buffer, 변환 색인 버퍼)`라는 것을 사용한다.
    - CPU가 TLB에서 먼저 페이징 테이블을 찾는다.
    - 단, TLB 하드웨어는 비싸고, 모든 페이지 테이블을 저장하고 있을 수는 없다는 단점이 있다.

#### (2) 세그먼테이션(segmentation) 기법

프로세스를 의미 단위인 여러 개의 세그먼트(segment)로 구성

- 작게는 프로그램을 구성하는 함수 하나 하나를 세그먼트로 정의
- 크게는 프로그램 전체를 하나의 세그먼트로 정의
- 일반적으로는 code, data, stack이 하나의 세그먼트로 정의됨

할당하는 공간의 크기가 프로세스에 따라 동적이기 때문에 외부 단편화가 발생하게 된다.

- 주소 변환 기법: 세그먼트 테이블(segment table)을 사용하여 물리적 메모리 주소로 변환된다.
  -  세그먼트의 번호, 시작 주소, 크기를 저장하고 있는 테이블이다.
  - 예) 세그먼트 번호 0이 base 1400, limit 1000으로 맵핑되어 있음 → 세그먼트 0번은 1400번 주소부터 시작해서 크기가 1000만큼 할당되어 있다는 의미









↓ 정리 중임...



## 5. 단편화 해결 방법

<br>

### 1) 페이징 기법

> 현대의 메모리 관리법

logical 메모리가 page table을 거쳐서 physical 메모리주소로 변환



페이징 기법이란 사용하지 않는 프레임을 페이지로 옮기고, 필요한 메모리를 페이지 단위로 프레임에 옮기는 방법을 말한다.



페이지 테이블은 각 프로세스마다 존재하는 구조임 => 프로세스마다 다른 주소값을 할당하기 위함

#### (1) One Level Page Table

![image](https://user-images.githubusercontent.com/93081720/167281980-8d9ff193-944a-43e0-ae9d-3f9c98b765ef.png)

<br>

#### (2) Two Level Page Table

- 바깥 테이블과 안쪽 테이블이 존재하는 구조 => one lvl 페이지 테이블의 공간적 비효율을 개선하기 위해 등장
  - 바깥 테이블은 안쪽 테이블의 entry를 가리키는 정보를 담고 있음
  - 시간적으로는 더 많이 걸림
  - 그냥 보기에는 공간적으로도 손해(왜냐하면 페이지 테이블이 똑같이 존재하니까) 같지만 실제로는 안 쓰는 공간에 대해서는 안쪽 테이블이 만들어지지 않기 때문에 공간적으로 이득임

![image](https://user-images.githubusercontent.com/93081720/167282420-453972bf-0ffc-4941-ad84-583863942b8a.png)

<br>

### 2) 세그먼테이션 기법



<br>

### 3) 메모리 풀 기법

필요한 메모리 공간을 사용할 크기, 개수만큼 사용자가 직접 지정하여 미리 할당받아 놓고 필요할 때마다 사용하고 반납하는 기법.

메모리 풀 없이 동적 할당과 메모리 해제를 반복하면 메모리 단편화가 발생해서 낭비가 있겠지만 메모리 풀을 사용할 경우 할당과 해제가 없기 때문에 단편화가 발생하지 않는다.

그러나 사용하지도 않을 메모리를 미리 할당해 놓는 점에서 메모리 누수가 있는 메모리 관리 기법이다.

<br>

-----

TLB => 캐시 메모리

메모리 접근 시가늘 줄일 수 있음, 다단계 테이블의 오버헤드를 줄일 수 있음



valid-invalid bit

- valid bit: 해당 주소의 frame에 그 프로세스를 구성하는 유효한 내용이 있음(접근 허용)
- invalid bit: 해당 주소의 frame에 유효한 내용이 없음(접근 불허)



protection bit

- page에 대한 접근 권한(연산에 대한 접근 권한)



Inverted Page Table

page table로 인한 공간적 오버헤드를 줄일 수는 있지만, 탐색을 위해 시간적으로 전부 탐색해야 한다는 단점이 존재

※ page table이 큰 이유

1) 모든 프로세스별로 그 논리적 메모리에 대응하는 모든 page에 대해 page table entry 존재
1) 대응하는 page가 메모리에 있든 없든 page table에는 entry가 존재함



Shared Page

- Shared Code
  - re-entrant code(=pure code)
  - 제약 조건
    - read-only로 하여 프로세스 간에 하나의 코드만 물리적 메모리에 올림
    - 모든 프로세스의 동일한 logical address space에 위치해 있어야함
- Private Code & Data
  - 각 프로세스들은 독자적으로 메모리에 올림
  - private data는 logical address space의 아무곳에나 와도 무방함

- 



### 5) Dynamic Relocation (동적 재할당)

![image](https://user-images.githubusercontent.com/93081720/166856667-b64ac8e2-be22-41b8-b788-8bafe88587f1.png)

#### (1) Relocation register (Base register)

- 접근할 수 있는 물리적 메모리의 기본값, 최솟값

#### (2) Limit register

- 논리적 주소의 범위
- 범위를 벗어난 주소를 요구하는 것은 악의적인 프로그램이므로 trap에 의해 사전 차단되며 이후, CPU 제어가 OS로 넘어가서 후속 조치(강제 abort 등)를 취함

![image](https://user-images.githubusercontent.com/93081720/166856629-faaafe43-6342-487e-8791-883da9df9522.png)

<br>
